{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GeorgeCrossIV/Product-Recommendation-Chatbot/blob/main/Vector_Search_Product_Recommendation_Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ee0e82f-95fa-4efa-84e3-9873d4dcdaf1",
      "metadata": {
        "id": "8ee0e82f-95fa-4efa-84e3-9873d4dcdaf1"
      },
      "source": [
        "# Getting Started with this notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58bc1d2f-7039-4d2a-950c-ff3686013c55",
      "metadata": {
        "id": "58bc1d2f-7039-4d2a-950c-ff3686013c55"
      },
      "source": [
        "- Create a new vector search enabled database in Astra. [astra.datastax.com](https://astra.datastax.com)\n",
        "- For the easy path, name the keyspace in that database \"vector_preview\" (otherwise be prepared to modify the CQL in this notebook)\n",
        "- Create a token with permissions to create tables\n",
        "- Download your secure-connect-bundle zip file.\n",
        "- Set up an open.ai API account and generate a key\n",
        "- Update the Keys & Environment Variables cell in the notebook with information from the token you generated and the name of your secure connect bundle file."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c1f964d-aa85-4b2f-a04c-71c295fe9d1e",
      "metadata": {
        "id": "2c1f964d-aa85-4b2f-a04c-71c295fe9d1e"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e57b18c-275c-40bf-8a71-bbb0c94b2a7b",
      "metadata": {
        "scrolled": true,
        "id": "3e57b18c-275c-40bf-8a71-bbb0c94b2a7b"
      },
      "outputs": [],
      "source": [
        "!pip install openai pandas jupyter-datatables cassandra-driver"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25d08ec4-0e7b-4819-933f-43ed5ff95e48",
      "metadata": {
        "id": "25d08ec4-0e7b-4819-933f-43ed5ff95e48"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01da99af-da9b-4f38-b841-d802ff23bf2f",
      "metadata": {
        "id": "01da99af-da9b-4f38-b841-d802ff23bf2f"
      },
      "outputs": [],
      "source": [
        "from cassandra.cluster import Cluster\n",
        "from cassandra.auth import PlainTextAuthProvider\n",
        "from cassandra.query import dict_factory\n",
        "from cassandra.query import SimpleStatement\n",
        "from google.colab import userdata\n",
        "import openai\n",
        "import numpy\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7a93b64-e9e9-41d1-95c9-dc9194a5ec8d",
      "metadata": {
        "id": "b7a93b64-e9e9-41d1-95c9-dc9194a5ec8d"
      },
      "source": [
        "# Keys & Environment Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebeb1df7-2dcc-4ba6-a941-49c68631bd49",
      "metadata": {
        "id": "ebeb1df7-2dcc-4ba6-a941-49c68631bd49"
      },
      "outputs": [],
      "source": [
        "# keys and tokens here\n",
        "openai_api_key = userdata.get('openai_api_key')\n",
        "openai.api_key = openai_api_key\n",
        "cass_user = userdata.get('cass_user')\n",
        "cass_pw = userdata.get('cass_pw')\n",
        "scb_path = '/content/secure-connect-cassio-db.zip'\n",
        "keyspace=\"chatbot\"\n",
        "table=\"products_table\"\n",
        "embed_data=False # set to True to reset the schema and create the embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a96369f4-d311-44c2-8469-f960a2a8718a",
      "metadata": {
        "id": "a96369f4-d311-44c2-8469-f960a2a8718a"
      },
      "source": [
        "# Select a model to compute embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "553fece5-8154-4e18-9610-ff4999bfe171",
      "metadata": {
        "id": "553fece5-8154-4e18-9610-ff4999bfe171"
      },
      "outputs": [],
      "source": [
        "model_id = \"text-embedding-ada-002\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bafd4fc1-84a4-4384-bb3e-42ecffab2455",
      "metadata": {
        "id": "bafd4fc1-84a4-4384-bb3e-42ecffab2455"
      },
      "source": [
        "# Connect to the Cluster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c5b0058-391d-421e-81a0-eb2f7fe684df",
      "metadata": {
        "id": "8c5b0058-391d-421e-81a0-eb2f7fe684df"
      },
      "outputs": [],
      "source": [
        "cloud_config= {\n",
        "  'secure_connect_bundle': scb_path\n",
        "}\n",
        "auth_provider = PlainTextAuthProvider(cass_user, cass_pw)\n",
        "cluster = Cluster(cloud=cloud_config, auth_provider=auth_provider, protocol_version=4)\n",
        "session = cluster.connect()\n",
        "session.set_keyspace('vector_preview')\n",
        "session"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0670b30f-927f-47da-b71d-0a99092c3f58",
      "metadata": {
        "id": "0670b30f-927f-47da-b71d-0a99092c3f58"
      },
      "source": [
        "# Drop / Create Schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acf0fd4c-8367-4d5f-983f-5aa7d14a8948",
      "metadata": {
        "id": "acf0fd4c-8367-4d5f-983f-5aa7d14a8948"
      },
      "outputs": [],
      "source": [
        "# only use this to reset the schema\n",
        "if embed_data:\n",
        "  session.execute(f\"\"\"DROP INDEX IF EXISTS {keyspace}.openai_desc\"\"\")\n",
        "  session.execute(f\"\"\"DROP TABLE IF EXISTS {keyspace}.{table}\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a941c487-1c6b-4f46-a0a3-305a95931d82",
      "metadata": {
        "id": "a941c487-1c6b-4f46-a0a3-305a95931d82"
      },
      "outputs": [],
      "source": [
        "# # Create Table\n",
        "if embed_data:\n",
        "  session.execute(f\"\"\"\n",
        "  CREATE TABLE IF NOT EXISTS {keyspace}.{table}\n",
        "  (product_id int,\n",
        "  chunk_id int,\n",
        "\n",
        "  product_name text,\n",
        "  description text,\n",
        "  price text,\n",
        "\n",
        "  openai_description_embedding vector<float, 1536>,\n",
        "  minilm_description_embedding vector<float, 384>,\n",
        "\n",
        "  PRIMARY KEY (product_id, chunk_id))\n",
        "  \"\"\")\n",
        "\n",
        "  # # Create Index\n",
        "  session.execute(f\"\"\"CREATE CUSTOM INDEX IF NOT EXISTS openai_desc ON {keyspace}.{table} (openai_description_embedding) USING 'org.apache.cassandra.index.sai.StorageAttachedIndex'\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1fe256f-9efb-41f0-8803-d99696c6089b",
      "metadata": {
        "id": "c1fe256f-9efb-41f0-8803-d99696c6089b"
      },
      "source": [
        "# Load the table with data and create text embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cec8fd49-90b7-4f8f-b6e8-50a34896e452",
      "metadata": {
        "id": "cec8fd49-90b7-4f8f-b6e8-50a34896e452"
      },
      "outputs": [],
      "source": [
        "if embed_data:\n",
        "  !wget https://raw.githubusercontent.com/GeorgeCrossIV/Product-Recommendation-Chatbot/main/ProductDataset.csv\n",
        "  products_list = pd.read_csv('ProductDataset.csv')\n",
        "  products_list"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This next step creates embeddings and inserts the data. It will take a few minutes to complete"
      ],
      "metadata": {
        "id": "EFLUwbc9vlkn"
      },
      "id": "EFLUwbc9vlkn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14eb4355-9fcd-4795-8406-aee98fd4b11f",
      "metadata": {
        "scrolled": true,
        "id": "14eb4355-9fcd-4795-8406-aee98fd4b11f"
      },
      "outputs": [],
      "source": [
        "if embed_data:\n",
        "  for id, row in products_list.iterrows():\n",
        "    # Create Embedding for each conversation row, save them to the database\n",
        "    text_chunk_length = 2500\n",
        "    text_chunks = [row.description[i:i + text_chunk_length] for i in range(0, len(row.description), text_chunk_length)]\n",
        "    for chunk_id, chunk in enumerate(text_chunks):\n",
        "      pricevalue = row.price if isinstance(row.price, str) else \"\"\n",
        "      full_chunk = f\"{chunk} price: {pricevalue}\"\n",
        "      embedding = openai.embeddings.create(input=full_chunk, model=model_id).data[0].embedding\n",
        "      query = SimpleStatement(\n",
        "                  f\"\"\"\n",
        "                  INSERT INTO {keyspace}.{table}\n",
        "                  (product_id, chunk_id, product_name, description, price, openai_description_embedding)\n",
        "                  VALUES (%s, %s, %s, %s, %s, %s)\n",
        "                  \"\"\"\n",
        "              )\n",
        "      display(row)\n",
        "\n",
        "      session.execute(query, (row.product_id, chunk_id, row.product_name, row.description, pricevalue, embedding))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fc20311-5fde-46b1-b194-4611866f4264",
      "metadata": {
        "id": "2fc20311-5fde-46b1-b194-4611866f4264"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Start using the index"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83f833ef-6555-452b-a903-9505c77b75b1",
      "metadata": {
        "id": "83f833ef-6555-452b-a903-9505c77b75b1"
      },
      "source": [
        "In the steps up to this point, we have been creating a schema and loading the table with data, including embeddings we generated through the OpenAI Embedding API.\n",
        "Now we are going to query that table and use the results to give ChatGPT some context to support it's response."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "466ca4e3-7bb6-485b-ac3a-788c1fe3658d",
      "metadata": {
        "id": "466ca4e3-7bb6-485b-ac3a-788c1fe3658d"
      },
      "source": [
        "# Convert a query string into a text embedding to use as part of the query"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37217051-b389-49eb-8b5b-6efb14d9f8c4",
      "metadata": {
        "id": "37217051-b389-49eb-8b5b-6efb14d9f8c4"
      },
      "source": [
        "This is where the real fun starts.  Provide a question or request to be used as the query.  The source sample database is mostly consumer electronics and appliances, so imagine you're talking to a customer service rep at Best Buy or another electronics store.\n",
        "\n",
        "Here we use the same API that we used to calculate embeddings for each row in the database, but this time we are using your input question to calculate a vector to use in a query."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e891b68c-5e31-4b6f-915f-f05f684529b4",
      "metadata": {
        "scrolled": true,
        "id": "e891b68c-5e31-4b6f-915f-f05f684529b4"
      },
      "outputs": [],
      "source": [
        "customer_input = \"What equipement would you recommend for a computer workstation setup costing less than $2000?\"\n",
        "\n",
        "embedding = openai.embeddings.create(input=customer_input, model=model_id).data[0].embedding\n",
        "display(embedding)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1036a24f-d527-410b-b73c-d2e191b792a5",
      "metadata": {
        "id": "1036a24f-d527-410b-b73c-d2e191b792a5"
      },
      "source": [
        "Let's take a look at what a query against a vector index could look like.  The query vector has the same dimensions (number of entries in the list) as the embeddings we generated a few steps ago for each row in the database."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed786879-c639-458c-84e4-b657b2fba9a1",
      "metadata": {
        "scrolled": true,
        "id": "ed786879-c639-458c-84e4-b657b2fba9a1"
      },
      "outputs": [],
      "source": [
        "query = SimpleStatement(\n",
        "    f\"\"\"\n",
        "    SELECT *\n",
        "    FROM {keyspace}.{table}\n",
        "    ORDER BY openai_description_embedding ANN OF {embedding} LIMIT 5;\n",
        "    \"\"\"\n",
        "    )\n",
        "display(query)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93edd66f-4ffc-4133-943e-b0266c704f49",
      "metadata": {
        "id": "93edd66f-4ffc-4133-943e-b0266c704f49"
      },
      "source": [
        "# Find the top 5 results using ANN Similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6be4acfe-bd54-462c-9f96-acae2228d633",
      "metadata": {
        "id": "6be4acfe-bd54-462c-9f96-acae2228d633"
      },
      "outputs": [],
      "source": [
        "results = session.execute(query)\n",
        "top_5_products = results._current_rows\n",
        "\n",
        "for row in top_5_products:\n",
        "  print(f\"\"\"{row.product_id}, {row.product_name}, {row.description}, {row.price}\\n\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbffc89a-b9c8-40d5-90b8-f2493eded2d8",
      "metadata": {
        "id": "cbffc89a-b9c8-40d5-90b8-f2493eded2d8"
      },
      "source": [
        "# Ask ChatGPT for some help (Prompt Engineering)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24d02afb-13b1-4c71-8610-90768e21989e",
      "metadata": {
        "id": "24d02afb-13b1-4c71-8610-90768e21989e"
      },
      "source": [
        "- Here we build a prompt with which we'll query ChatGPT.  Note the \"roles\" in this little conversation give the LLM more context about who that part of the conversation is coming from.\n",
        "- This may take 10-20 seconds to return, so be patient."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f517ae3-0f27-418b-93d4-6eb02a781080",
      "metadata": {
        "id": "6f517ae3-0f27-418b-93d4-6eb02a781080"
      },
      "outputs": [],
      "source": [
        "\n",
        "message_objects = []\n",
        "message_objects.append({\"role\":\"system\",\n",
        "                        \"content\":\"You're a chatbot helping customers with questions and helping them with product recommendations\"})\n",
        "\n",
        "message_objects.append({\"role\":\"user\",\n",
        "                        \"content\": customer_input})\n",
        "\n",
        "message_objects.append({\"role\":\"user\",\n",
        "                        \"content\": \"Please give me a detailed explanation of your recommendations\"})\n",
        "\n",
        "message_objects.append({\"role\":\"user\",\n",
        "                        \"content\": \"Please be friendly and talk to me like a person, don't just give me a list of recommendations\"})\n",
        "\n",
        "message_objects.append({\"role\": \"assistant\",\n",
        "                        \"content\": \"I found these 3 products I would recommend\"})\n",
        "\n",
        "products_list = []\n",
        "\n",
        "for row in top_5_products:\n",
        "    brand_dict = {'role': \"assistant\", \"content\": f\"{row.description}\"}\n",
        "    products_list.append(brand_dict)\n",
        "\n",
        "message_objects.extend(products_list)\n",
        "message_objects.append({\"role\": \"assistant\", \"content\":\"Here's my summarized recommendation of products, and why it would suit you:\"})\n",
        "\n",
        "completion = openai.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=message_objects\n",
        ")\n",
        "print(completion.choices[0].message.content)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}